{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challengue LATAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Importante*: Ejecute la siguiente celda para instalar las dependencias necesarias.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in c:\\users\\gt\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.12.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7.0 in c:\\users\\gt\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from emoji) (4.12.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutar el siguiente bloque de c√≥digo, que es necesario para el funcionamiento de todos los m√©todos posteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "\n",
    "file_path = \"farmers-protest-tweets-2021-2-4.json\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with ZipFile(\"../tweets/tweets.json.zip\", 'r') as zObject: \n",
    "        zObject.extractall('.') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema 1: Top 10 fechas con mayor cantidad de tweets por usuario\n",
    "### 1. Optimizaci√≥n de tiempo de ejecuci√≥n\n",
    "En este apartado para la optimizaci√≥n de tiempo de ejecuci√≥n se va cargar todos los datos de fechas y usernames en una sola operaci√≥n, esto simplifica el an√°lisis y mejora el rendimiento general del proceso\n",
    "\n",
    "Optimizaci√≥n Adicional:\n",
    "Se observa que el tiempo de ejecuci√≥n demora m√°s que el realizado para optimizaci√≥n de memoria, se podr√≠a explorar la divisi√≥n del conjunto de datos en secciones m√°s peque√±as y la implementaci√≥n de t√©cnicas de threading para procesamiento paralelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de Ejecucion: 7.991407155990601 \n",
      "Resultados Obtenidos: \n",
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n"
     ]
    }
   ],
   "source": [
    "from q1_time import q1_time\n",
    "\n",
    "start_time = time()\n",
    "result = q1_time(file_path=file_path)\n",
    "print(f\"Tiempo de Ejecucion: {time() - start_time} \")\n",
    "print(\"Resultados Obtenidos: \")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Optimizaci√≥n de memoria en uso\n",
    "\n",
    "Para este apartado, se opt√≥ por procesar el archivo de forma secuencial, analizando cada l√≠nea individualmente. Esta estrategia reduce significativamente el consumo de memoria en comparaci√≥n con el primer apartado. Adem√°s resulta ser m√°s eficiente en t√©rminos de tiempo de ejecuci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de Ejecucion: 5.05846643447876 \n",
      "Resultados Obtenidos: \n",
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n"
     ]
    }
   ],
   "source": [
    "from q1_memory import q1_memory\n",
    "\n",
    "start_time = time()\n",
    "result = q1_memory(file_path=file_path)\n",
    "print(f\"Tiempo de Ejecucion: {time() - start_time} \")\n",
    "print(\"Resultados Obtenidos: \")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema 2: Top 10 emojis m√°s usados con su conteo correspondiente\n",
    "### 1. Optimizaci√≥n de tiempo de ejecuci√≥n\n",
    "Para abordar este problema se emple√≥ la librer√≠a emoji previamente instalada en el primer bloque de este notebook el cual permite extraer emojis de cadenas de texto. \n",
    "Utilizando esta librer√≠a, se agrup√≥ el contenido de todos los tweets en un √∫nico string para analizarlo y obtener todos los emojis. Este enfoque result√≥ ser m√°s lento que el procesamiento de optimizaci√≥n de uso de memoria, posiblemente debido al tama√±o del archivo .json.\n",
    "\n",
    "Optimizaci√≥n Adicional:\n",
    "\n",
    "Para optimizar el tiempo de ejecuci√≥n, se pueden implementar estrategias como procesar el archivo en lotes para reducir la carga en cada operaci√≥n y aplicar multiprocesamiento para ejecutar an√°lisis en paralelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de Ejecucion: 17.018301010131836 \n",
      "Resultados Obtenidos: \n",
      "[('üôè', 5049), ('üòÇ', 3072), ('üöú', 2972), ('üåæ', 2182), ('üáÆüá≥', 2086), ('ü§£', 1668), ('‚úä', 1651), ('‚ù§Ô∏è', 1382), ('üôèüèª', 1317), ('üíö', 1040)]\n"
     ]
    }
   ],
   "source": [
    "from q2_time import q2_time\n",
    "\n",
    "start_time = time()\n",
    "result = q2_time(file_path=file_path)\n",
    "print(f\"Tiempo de Ejecucion: {time() - start_time} \")\n",
    "print(\"Resultados Obtenidos: \")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Optimizaci√≥n de memoria en uso\n",
    "\n",
    "Para esta secci√≥n se utiliz√≥ la misma l√≥gica de la optimizaci√≥n de tiempo de ejecuci√≥n, procesando el archivo en forma secuencial, analizando cada l√≠nea individualmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de Ejecucion: 17.377023935317993 \n",
      "Resultados Obtenidos: \n",
      "[('üôè', 5049), ('üòÇ', 3072), ('üöú', 2972), ('üåæ', 2182), ('üáÆüá≥', 2086), ('ü§£', 1668), ('‚úä', 1651), ('‚ù§Ô∏è', 1382), ('üôèüèª', 1317), ('üíö', 1040)]\n"
     ]
    }
   ],
   "source": [
    "from q2_memory import q2_memory\n",
    "\n",
    "start_time = time()\n",
    "result = q2_memory(file_path=file_path)\n",
    "print(f\"Tiempo de Ejecucion: {time() - start_time} \")\n",
    "print(\"Resultados Obtenidos: \")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema 3: Top 10 usuarios m√°s influyentes seg√∫n el conteo de menciones (@)\n",
    "### 1. Optimizaci√≥n de tiempo de ejecuci√≥n\n",
    "Para este problema se va implementar una funci√≥n que cuenta los usernames mencionados en el archivo JSON de tweets. Utilizando la clase Counter de la biblioteca collections, se lee el archivo l√≠nea por l√≠nea para extraer la lista de usuarios dentro de mentionedUsers.\n",
    "\n",
    "Optimizaci√≥n Adicional:\n",
    "\n",
    "Utilizar formatos como CSV o Parquet podr√≠a mejorar el rendimiento, ya que son m√°s eficientes en t√©rminos de lectura y procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de Ejecucion: 5.206971168518066 \n",
      "Resultados Obtenidos: \n",
      "[('narendramodi', 2265), ('Kisanektamorcha', 1840), ('RakeshTikaitBKU', 1644), ('PMOIndia', 1427), ('RahulGandhi', 1146), ('GretaThunberg', 1048), ('RaviSinghKA', 1019), ('rihanna', 986), ('UNHumanRights', 962), ('meenaharris', 926)]\n"
     ]
    }
   ],
   "source": [
    "from q3_time import q3_time\n",
    "\n",
    "start_time = time()\n",
    "result = q3_time(file_path=file_path)\n",
    "print(f\"Tiempo de Ejecucion: {time() - start_time} \")\n",
    "print(\"Resultados Obtenidos: \")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Optimizaci√≥n de memoria en uso\n",
    "\n",
    "Para esta secci√≥n se utiliz√≥ la misma l√≥gica de la optimizaci√≥n de tiempo de ejecuci√≥n, procesando el archivo en forma secuencial, l√≠nea por l√≠nea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- TIEMPO DE EJECUCION: 5.28658390045166 \n",
      "RESULTADO: \n",
      "[('narendramodi', 2265), ('Kisanektamorcha', 1840), ('RakeshTikaitBKU', 1644), ('PMOIndia', 1427), ('RahulGandhi', 1146), ('GretaThunberg', 1048), ('RaviSinghKA', 1019), ('rihanna', 986), ('UNHumanRights', 962), ('meenaharris', 926)]\n"
     ]
    }
   ],
   "source": [
    "from q3_memory import q3_memory\n",
    "\n",
    "start_time = time()\n",
    "result = q3_memory(file_path=file_path)\n",
    "print(f\"-- TIEMPO DE EJECUCION: {time() - start_time} \")\n",
    "print(\"RESULTADO: \")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comentario Final\n",
    "\n",
    "Para optimizar el an√°lisis de datos para estos problemas desde la perspectiva de Cloud, espec√≠ficamente utilizando Azure, se podr√≠a utilizar Azure Data Lake Storage para almacenar los archivos de tweets, facilitando el acceso eficiente a grandes vol√∫menes de datos. Azure Data Factory podr√≠a emplearse para orquestar el flujo de datos, permitiendo la extracci√≥n, transformaci√≥n y carga (ETL) de los datos desde diferentes fuentes. Adem√°s, implementar Azure Functions permitir√≠a ejecutar el procesamiento en paralelo y en respuesta a eventos, mejorando la escalabilidad. Tambi√©n considerar el uso de Azure Databricks ser√≠a √∫til para realizar an√°lisis en lote utilizando Apache Spark, aprovechando el procesamiento distribuido."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
